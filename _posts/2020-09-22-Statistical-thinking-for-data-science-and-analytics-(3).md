---
title: Statistical thinking for data science and analytics (3)
tag: 데이터와분석적사고
---

# Data and Vector
우리가 조사하고자 하는 샘플이 있다고 가정해봅시다. 그러면, 이 샘플은 각각 고유한 특성이 있겠죠. 예시를 들어 설명해보자면

1. 2019년 한국 미성년자의 스마트폰 일일 사용 시간 데이터에 관심이 있다고 가정하면, 각 데이터는 사용 시간에 대한 추가 정보(연령, 성별 등)로 구성됩니다.
2. 이 수업을 듣는 학생들을 조사할 때, 학생들의 이름 GPA, SAT 점수 등을 수집할 수 있습니다.

이렇게 객체의 여러 특성을 표현하는 것은 **벡터**로 가능합니다.
벡터는 순서가 지정되어 있는 튜플입니다.

# Why Vector?
간단한 예제 수준의 데이터 가공은 사람의 힘으로도 문제 없지만, 정보의 단위가 커지면 Raw Data에서 얻고자 하는 정보를 뽑아내는 것이 어렵습니다. **표본이나 공변량이 많으면 그렇게 되겠죠.**   
또한 벡터를 이용하면 주어젠 데이터 세트에서 정보를 추출하기 쉽습니다. **평균이나 비율, 분산 등을 연산하기 편리하기 때문입니다.**

상술했듯, 주어진 데이터에서 유용한 정보를 추출하기 위해서는 벡터에 대한 작업(주로 연산)이 필요합니다.
이때 벡터에 대한 작업은 **잘 정의되어야 합니다.**   
잘 정의되었다. 말이 어색하죠? 이해를 돕기 위해 잘 정의되지 않은 경우를 예시로 들어보겠습니다.
* 첫번째 사람의 국적과 두 번째 사람의 혈액형을 비교하기 : 두 가지 특성이 일치하지 않으므로 non-sense
* 14세 이하 학생들의 합 : 학생들은 합이 가능한 양적 가치가 아니므로 non-sense

# Vector Space
> '벡터 공간'은 작업이 잘 정의된 벡터 집합
> 

벡터 공간을 만족하려면
* 벡터 연산이 후술할 8개의 공리를 충족해야 함
* 그 연산은 두개

**벡터 연산**
* 첫 번째 연산 : **vector addition**이고, 주로 "+"로 표시됩니다.  벡터공간 V에서 임의의 벡터 v와 w를 활용해 세 번째 벡터를 할당합니다. (V × V → V) 일반적으로 v+w라고 쓰고, **벡터의 합**이라고 합니다.
* 두 번째 연산 : **scalar multiplication**이고, F의 요소 a (a ∈ F)와 V의 요소 v (v ∈ V)를 이용해 V의 또 다른 요소인 벡터 av를 생성합니다. (F × V → V) **벡터의 스칼라곱**이라고 합니다.

**공리**
* **Associativity of addition**(덧셈의 결합법칙) : u + (v + w) = (u + v) +w
* **Commutativity of addition**(덧셈의 교환법칙) : u + v = v + u
* **Identity element of addtion**(덧셈의 항등요소) : **모든 v ∈ V**에 대해  v + 0 = v를 만족하는 0 ∈ V가 있습니다. (영벡터가 항상 존재)
*  **Inverse elements of addtion**(역 요소) : **모든 v ∈ V**에 대해 v의 역요소(**가법 역행**)인 −v ∈ V가 있습니다. v + (-v) = 0을 만족합니다.
*  **스칼라 곱과 필드 곱의 호환** : a(bv) = (ab)v
* **multiplicative identity** : 1v = v입니다. 1을 스칼라곱한 벡터는 언제나 그 벡터가 됩니다.
*  **벡터합에 대한 스칼라 곱 분배** : a(u + v) = au + av
*  **필드합에 대한 스칼라 곱 분배** : (a + b)v = av + bv

**벡터 연산 예시**       
![](https://i.ibb.co/SdPjXL6/example.jpg)

두 번째 연산 같은 경우 굉장히 이상하죠? 이러한 연산은 컴퓨터과학에서 광범위하게 사용됩니다.      
컴퓨터 프로그래밍은 여러 논리 연산을 가지고 있습니다. 컴퓨터에게 무엇이 True이고 False인지 명시하기 위해서죠. 예를 들어
* -3이 음수인가? → true       
* 내 GPA가 4.6을 넘는가? → false

와 같은 것들 말이죠.

**논리 연산**은 둘 이상을 연결해 참 또는 거짓으로 출력합니다. 세 가지의 연산자가 있습니다.
* **AND** : 두개 다 참일때만 참을 출력하고, 이외에는 거짓
* **OR** : 둘 중 하나라도 참이면 참, 둘다 거짓이면 거짓
* **XOR** : 둘중 하나만 참이어야 참, 둘다 참이거나 둘다 거짓이면 거짓

앞서 얘기했던 벡터 연산 예시를 다시 살펴보죠.     
F = {0,1} and V = {0,1}     
여기서 0은 FALSE, 1은 TRUE에 해당합니다.    
여기서의 **연산 "+"는, 우리가 배운 XOR 연산과 같습니다.** 또한 **"·" 연산은 우리가 배운 AND 연산과 같습니다.**     
![](https://i.ibb.co/ggntbWx/op.jpg)

**벡터공간이 아닌 케이스**  
![](https://i.ibb.co/RD7f4tp/no1.jpg)       
만약 F의 요소 0.5와 V의 요소 (1,1)을 선택했다고 가정해 봅시다. 스칼라 곱 연산시 (0.5,0.5)가 되는데, **이 연산의 결과가 V의 요소(자연수)가 아닙니다.**

![](https://i.ibb.co/txncs0T/no2.jpg)     
만약 F의 요소 -1과 V의 요소 (1,2,3)을 선택했다고 가정해 봅시다. 스칼라 곱 연산 시 (-1,-2,-3)이 되는데, **이 연산의 결과가 V의 요소(양의 실수)가 아닙니다.** 또한 V의 요소 v가 있다고 가정할 때 v + (-v) = 0을 만족하는 **역연산 요소**가 있어야 하는데, V에는 이것을 만족하는 요소가 없습니다.

# Magnitude of a Vector
벡터를 배웠으니 벡터의 요소에 대해서도 이해를 해야합니다. 벡터를 구별하는 방법에는 **vector magnitude**와 **vector direction**이 있습니다. 고교 수준에서 충분히 배우고 오기 때문에, 간단하기 리뷰만 하도록 하겠습니다.

* **Suppose two vectors v1 = (1, 1) and v2 = (3, 3) in R2. Do they have the same magnitude?** : 아니요. 벡터의 방향은 같지만 크기는 다릅니다.
* **Suppose two vectors v1 = (1, 1) and v3 = (1, −1) in R2. Do they have the same magnitude?** : 예. 방향은 다르지만 크기는 같습니다.
* **Suppose two vectors v1 = (1, 1) and v4 = (−1, 2) in R2. Do they have the same magnitude?** : 아니요. 방향도 다르고 크기도 다릅니다.
